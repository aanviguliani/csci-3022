{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a id='top'></a>\n",
    "\n",
    "# Homework 2: Data Visualization and Probability Analysis \n",
    "***\n",
    "\n",
    "**Name**: Aanvi Guliani\n",
    "\n",
    "***\n",
    "\n",
    "This assignment is due on Canvas by **MIDNIGHT on Monday September 14**. Your solutions to theoretical questions should be done in Markdown directly below the associated question.  Your solutions to computational questions should include any specified Python code and results as well as written commentary on your conclusions.  Remember that you are encouraged to discuss the problems with your classmates, but **you must write all code and solutions on your own**.\n",
    "\n",
    "**NOTES**: \n",
    "\n",
    "- Any relevant data sets should be available under the **Data** module on Canvas. To make life easier on the graders if they need to run your code, do not change the relative path names here. Instead, move the files around on your computer.\n",
    "- If you're not familiar with typesetting math directly into Markdown then by all means, do your work on paper first and then typeset it later.  Remember that there is a [reference guide](https://math.meta.stackexchange.com/questions/5020/mathjax-basic-tutorial-and-quick-reference) linked on Canvas on writing math in Markdown. **All** of your written commentary, justifications and mathematical work should be in Markdown.\n",
    "- Because you can technically evaluate notebook cells is a non-linear order, it's a good idea to do Kernel $\\rightarrow$ Restart & Run All as a check before submitting your solutions.  That way if we need to run your code you will know that it will work as expected. \n",
    "- It is **bad form** to make your reader interpret numerical output from your code.  If a question asks you to compute some value from the data you should show your code output **AND** write a summary of the results in Markdown directly below your code. \n",
    "- 95 points of this assignment are in problems.  The remaining 5 are for neatness, style, and overall exposition of both code and text.\n",
    "- This probably goes without saying, but... For any question that asks you to calculate something, you **must show all work and justify your answers to receive credit**. Sparse or nonexistent work will receive sparse or nonexistent credit. \n",
    "\n",
    "---\n",
    "**Shortcuts:**  [Problem 1](#p1) | [Problem 2](#p2) | [Problem 3](#p3) |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to top](#top)\n",
    "\n",
    "<br>\n",
    "\n",
    "<a id='p1'></a>\n",
    "\n",
    "## (15 points) Problem 1: Theory (Median Distance)\n",
    "***\n",
    "\n",
    "One way we conceptualize many data science questions is asking for the \"best choice\" of some parameter on data set.  We should be able to justify that our measures of centrality should in some way be the \"best\" ways to represent the data.\n",
    "\n",
    "\n",
    "In lecture, we may have discussed the following important property of the mean:\n",
    "\n",
    "\n",
    "The *sample mean* of data $X_1, X_2, \\dots X_n$ is the unique minimizer $c$ of the function $$f(c)=\\sum_{i=1}^n \\left(X_i-c \\right)^2. $$\n",
    "\n",
    "The proof of that claim is as follows:\n",
    "\n",
    "**Proof:**\n",
    "\n",
    "Differentiating yields\n",
    "$$f'(c)=\\frac{df}{dc}\\sum_{i=1}^n \\left(X_i-c \\right)^2 =\\sum_{i=1}^n-2(X_i-c).$$ \n",
    "\n",
    "Setting $f'(c)=0$ gives\n",
    "\n",
    "$$0=\\sum_{i=1}^n-2(X_i-c)$$\n",
    "$$=2nc-2\\sum_{i=1}^n X_i$$\n",
    "$$\\implies\\qquad  c=\\frac{\\sum_{i=1}^n X_i}{n}=\\bar{X}$$\n",
    "\n",
    "***\n",
    "\n",
    "### Your exercise:\n",
    "\n",
    "You are tasked with recreating a *similar* proof.  Prove the following:\n",
    "\n",
    "The *median* of data $X_1, X_2, \\dots X_n$ is the possibly non-unique minimizer $c$ of the function $$f(c)=\\sum_{i=1}^n |X_i-c| $$\n",
    "\n",
    "A few things to think about:\n",
    "\n",
    " - how do we differentiate the absolute value function?\n",
    " - what conditions might make the median non-unique in this case?  If it's nonunique, what possible values of $c$ still minimize the function $f$?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Proof**  \n",
    "Break our absolute value into a piecewise function:  \n",
    "$$|X_i-c| = \\left\\{\n",
    "\\begin{array}{ll}\n",
    "      x_i-c & x_i-c \\geq0 \\\\\n",
    "      -(x_i-c) & x_i-c < 0 \\\\\n",
    "\\end{array} \n",
    "\\right.$$\n",
    "  \n",
    "Differentiating gives us:  \n",
    "$$\\dfrac{d}{dc}|X_i-c| = \\left\\{\n",
    "\\begin{array}{ll}\n",
    "      -1 & x_i-c \\geq0 \\\\\n",
    "      1 & x_i-c < 0 \\\\\n",
    "\\end{array} \n",
    "\\right.$$  \n",
    " \n",
    "$$f'(c) = \\dfrac{d}{dc}\\sum_{i=1}^n |X_i-c| = \\dfrac{d}{dc}|X_i-c| = \\left\\{\n",
    "\\begin{array}{ll}\n",
    "      \\sum_{i=1}^n-1 & x_i-c \\geq0 \\\\\n",
    "      \\sum_{i=1}^n1 & x_i-c < 0 \\\\\n",
    "\\end{array} \n",
    "\\right.$$ \n",
    "\n",
    "\n",
    "Since c is a minimizer, $f'(c)=0$. For this to be true, there must be an equal number of instances where $x_i-c \\geq 0$ and $x_i-c < 0$. This means that there must be an equal amount of numbers where $x_i \\geq c$ and $x_i < c$. This is the \"middle point\" of the data, or the median.  \n",
    "\n",
    "Thus, The *median* of data $X_1, X_2, \\dots X_n$ is the possibly non-unique minimizer $c$ of the function $$f(c)=\\sum_{i=1}^n |X_i-c| $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to top](#top)\n",
    "<a id='p2'></a>\n",
    "\n",
    "## (40 pts) Problem 2: Computation (Streaming Means)\n",
    "***\n",
    "\n",
    "Data science is often divided into two categories: questions of *what* the best value might be to repreesnt a data problem, and questions of *how* to compute that data value.  Question 1 - and prior lectures - should tell you that computing the mean is valuable!  But *how* do we compute the mean?\n",
    "\n",
    "Let $x_1, x_2, \\ldots, x_n$ be $n$ observations of a variable of interest.  Recall that the sample mean $\\bar{x}_n$ and sample variance $s^2_n$ are given by \n",
    "<a id='eq1'></a>\n",
    "$$\n",
    "\\bar{x}_n = \\frac{1}{n}\\sum_{k=1}^n x_k \\quad \\textrm{and} \\quad s^2_n = \\frac{1}{n-1}\\sum_{k=1}^n \\left( x_k - \\bar{x}_n\\right)^2 \\qquad \\tag{Equation 1}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part A**:\n",
    "\n",
    "How many computations - floating point operations: addition, subtraction, multiplication, division each count as 1 operation - are required to compute the mean of the data set with $n$ observations?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution**  \n",
    "For a data set with n observations, it takes **n+1** operations to calculate the mean of the data set. To figure this out, I created a modified version of the python function (added below) to calculate the sample mean. Along with calculating the mean, wherever a floating point operation occurred, I incremented a variable ops by 1. Using multiple test cases, I arrived at the conclusion that there were **n+1** calculations for for a list of length n."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n =  6 ; ops =  7\n",
      "n =  7 ; ops =  8\n",
      "n =  8 ; ops =  9\n",
      "n =  1 ; ops =  2\n"
     ]
    }
   ],
   "source": [
    "# modified version of mean function to calculate number of ops. \n",
    "# since we are only interested in ops, we don't have to calculate the mean, but it's an extra check to make sure\n",
    "# calculations and therefore number of ops are correct\n",
    "\n",
    "def calcMean(myList):\n",
    "    length = len(myList)\n",
    "    mean = 0\n",
    "    #variable to keep track of number of operations\n",
    "    ops = 0\n",
    "    for i in range(0,length):\n",
    "        #accumulate sum of list values\n",
    "        mean += myList[i]\n",
    "        #since an op occurs (addition), increment ops var\n",
    "        ops += 1\n",
    "    #now that we have sum of values, divide it by length of the list\n",
    "    mean = mean / length\n",
    "    #print(mean)\n",
    "    #since this is an op (division), increment ops var\n",
    "    ops += 1\n",
    "    #instead of returning the mean, return the number of ops\n",
    "    return ops\n",
    "    \n",
    "#test cases\n",
    "A = [1,1,1,1,1,1]\n",
    "B = [2,1,2,1,2,2,2]\n",
    "C = [0,1,12,3,4,5,6,7]\n",
    "D = [1]\n",
    "\n",
    "print(\"n = \",len(A), \"; ops = \", calcMean(A))\n",
    "print(\"n = \",len(B), \"; ops = \", calcMean(B))\n",
    "print(\"n = \",len(C), \"; ops = \", calcMean(C))\n",
    "print(\"n = \",len(D), \"; ops = \", calcMean(D))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part B**:\n",
    "\n",
    "Now suppose our data is *streaming*- we slowly add observations one at a time, instead of seeing the entire data set at once.  We are still interested in the mean, so if we stream the data set `[4,6,0,10, ...]`, we first compute the mean of the the first data point `[4]`, then we recompute the mean of the first two points `[4,6]`, then we recompute the mean of three `[4,6,0]`, and so forth.\n",
    "\n",
    "Suppose we recompute the mean from scratch after each and every one of our $n$ observations are one-by-one added to our data set.  How many floating point operations are spent computing (and re-computing) the mean of the data set?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution**  \n",
    "For every added observation, the mean function is called again with one added observation. We know that for a dataset with n observations, there are (n+1) operations occurring. Applying these same principles:  \n",
    "$$\n",
    "ops = (1+1) + (2+1) + (3+1) + ... (n+1)  \\\\\n",
    "    = \\sum_{i=1}^{n} (i+1)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should be convinced that streaming a mean costs a lot more computer time than just computing once!\n",
    "\n",
    "In this problem we explore a smarter method for such an _online_ computation of the mean.  \n",
    "\n",
    "**Result**: The following relation holds between the mean of the first $n-1$ observations and the mean of all $n$ observations: \n",
    "\n",
    "$$\n",
    "\\bar{x}_n = \\bar{x}_{n-1} + \\frac{x_n - \\bar{x}_{n-1}}{n}\n",
    "$$\n",
    "\n",
    "\n",
    "A proof of this result is in the [Appendix](#Appendix) after problem 3, and requires some careful manipulations of the sum $\\bar{x}_n$.  Your task will be to computationally verify and utilize this result.\n",
    "\n",
    "**Part C**: Write a function `my_sample_mean` that takes as its input a numpy array and returns the mean of that numpy array using the formulas from class ([Equation 1](#eq1)). Write another function `my_sample_var` that takes as its input a numpy array and returns the variance of that numpy array, again using the formulas from class ([Equation 1](#eq1)). You may **not** use any built-in sample mean or variance functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_sample_mean(arr):\n",
    "    # define variables length and mean for code readability\n",
    "    length = len(arr)\n",
    "    mean = 0\n",
    "    \n",
    "    # for loop to sum up all values in the array\n",
    "    for i in range(0,length):\n",
    "        mean += arr[i]\n",
    "        \n",
    "    #divide the sum of all values in array by length of array + return\n",
    "    mean = mean / length\n",
    "    return mean\n",
    "\n",
    "def my_sample_var(arr):\n",
    "    # get the mean of data set by calling my_sample_mean fcn - define length of array / summation for code readability\n",
    "    mean = my_sample_mean(arr)\n",
    "    length = len(arr)\n",
    "    summation = 0\n",
    "    \n",
    "    # get ∑𝑘=1𝑛(𝑥𝑘−𝑥¯𝑛)2 by looping through the array - store in summation var\n",
    "    for i in range(0,length):\n",
    "        summation += ((arr[i] - mean)**2)\n",
    "        \n",
    "    # calculate summation / (n-1) and return\n",
    "    return (summation/(length-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part D**: Use your functions from Part B to compute the sample mean and sample variance of the following array, which contains the minutes late that the BuffBus is running on Friday afternoon.\n",
    "\n",
    "`bus = [312, 4, 10, 0, 22, 39, 81, 19, 8, 60, 80, 42]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample mean:  56.416666666666664\n",
      "Sample variance: 7274.628787878787\n"
     ]
    }
   ],
   "source": [
    "#define \n",
    "bus = [312, 4, 10, 0, 22, 39, 81, 19, 8, 60, 80, 42]\n",
    "print(\"Sample mean: \", my_sample_mean(bus))\n",
    "print(\"Sample variance:\", my_sample_var(bus))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part E**: Implement a third function called `update_mean` that implements the formula discussed after part B. Note that this function will need to take as its input three things: $x_n$, $\\bar{x}_{n-1}$ and $n$, and returns $\\bar{x}_{n}$. A function header and return statement are provided for you. This function may be auto-graded, so please do not change the given header API - the order of inputs matters! If you change it, you might lose points.\n",
    "\n",
    "Use this function to compute the values that you get from taking the mean of the first buff buses' lateness, the first two buff buses' lateness, the first three buff buses' lateness, and so on up to all of the `bus` data points from **Part D**. Store your streaming bus means in a numpy array called `buffbus_bad_means`.  Report all 12 estimates in `buffbus_bad_means`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given API:\n",
    "def update_mean(prev_mean, xn, n):\n",
    "    # calculate now mean and return\n",
    "    now_mean = prev_mean + ((xn-prev_mean)/n)\n",
    "    return now_mean\n",
    "\n",
    "# define buffbus_bad_means as an numpy array w/ length of bus with all zeroes / define new mean as 0 for first call\n",
    "bus = [312, 4, 10, 0, 22, 39, 81, 19, 8, 60, 80, 42]\n",
    "buffbus_bad_means = np.zeros(len(bus))\n",
    "newMean = 0\n",
    "\n",
    "# loop through bus array, call update_mean with new_mean var, xn (bus[i]) and n to reassign val of new mean\n",
    "# store that value in buffbus_bad_means array at index i\n",
    "for i in range (0,len(bus)):\n",
    "    newMean = update_mean(newMean,bus[i],i+1)\n",
    "    buffbus_bad_means[i] = newMean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Array Values Stored**  \n",
    "buffbus_bad_means = [312.0, 158.0, 108.66666666666666, 108.66666666666666, 81.5, 69.6, 64.5, 66.85714285714286, 60.875, 55.0, 55.5, 57.72727272727273, 56.416666666666664]  \n",
    "\n",
    "Looking at the array, the last value in buffbus_bad_means should have the sample mean of the entire '**bus**' array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To ensure your function complies with the given API, run this small test, where we suppose we have a mean of $\\bar{x}_n = 1$ with the first $2$ data points (`prev_mean`), and we update this with the 3rd ($n=3$) data point which is $x_3=2$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert update_mean(1,2,3)==4/3, \"Warning: function seems broken.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part F**:\n",
    "\n",
    "How many floating point operations were spent computing the final result in your code in **part E**?  Is this truly better than the uninformed approach from **part B**?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer**  \n",
    "Looking at the code, we see that for each call to update_mean, there are three floating point observations. The first operation is subtracting $x_n$ from $\\bar{x}_{n-1}$, the second operation is dividing $x_n - \\bar{x}_{n-1}$ by $n$, and the third operation is adding this to $\\bar{x}_{n-1}$.  \n",
    "  \n",
    "Now it's just a matter of finding out how many calls to update_mean we have in a dataset of n observations. Since for each element in the dataset we make a new call to update_mean, for a dataset of length $n$, we have $n$ calls to update_mean.  \n",
    "  \n",
    "Putting these two together, we find that for a dataset of length $n$, there are $3n$ floating point operations to calculate the sample mean of the dataset.  \n",
    "  \n",
    "For small datasets, specifically datasets of length 1 or 2, the approach in part E would take more operations than the approach from part B. With a dataset of length 3, they would require the same number of operations. However, using the approach datasets of length greater than 3 would be the better option. In general, if we are working with data, it means that we probably expect to see more than 3 data points, so I would recommend using the approach from part E regardless of the size of the data set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to top](#top)\n",
    "\n",
    "<a id='p3'></a>\n",
    "\n",
    "## (40 pts) Problem 3: Data (Probability and Histograms)\n",
    "*** \n",
    "The sinking of the RMS Titanic was a terrible tragedy that saw the loss of many lives. Even within this tragedy, thanks to the combinations of the records of the White Star Line and the thorough nature of follow-up research after the accident we have some records that can help us try to piece together the course of events on board the ship. Many of the historians and other researchers who have investigated this event have speculated as to what exactly happened.\n",
    "\n",
    "We have the data on survival rates by class, gender, and age, so let's figure out whether there is evidence for some of these scenarios. Access the Titanic data in `titanic_data.csv` and store it in a Pandas DataFrame. The data contains information pertaining to class status (**Pclass**), survival (**Survived**), and gender (**Sex**) of passengers, among other things. Be sure to use the `titanic_data.csv` data set, *not* the `clean_titanic_data` file or `dirty_titanic_data` file from the in-class notebook exercises."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>36.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>27.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>63.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  36.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  18.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  14.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  27.0      1   \n",
       "4                           Allen, Mr. William Henry    male  63.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filepath = 'titanic_data.csv'\n",
    "df = pd.read_csv(filepath)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part A**:\n",
    "Based on the overall population of passengers, report the probability of survival.\n",
    "\n",
    "$$P(Survived=1)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The probability of survival based on the overall population of passengers is:  0.39\n"
     ]
    }
   ],
   "source": [
    "# probability of survival based on overall population\n",
    "# formula: (# survived) / (# total passengers)\n",
    "\n",
    "# get total survived by summing the count of rows where survived = 1, get total passengers by getting total rows in df\n",
    "total_survived = np.sum(df['Survived'] == 1)\n",
    "total_passengers = df.shape[0]\n",
    "\n",
    "# calculate probability, round it to two decimals for readability, and print it\n",
    "prob_survival = (total_survived / total_passengers).round(2)\n",
    "print(\"The probability of survival based on the overall population of passengers is: \", prob_survival)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part B**: \n",
    "Some claim that the final hours aboard the RMS Titanic were marked by \"class warfare\" in which the people with first-class tickets took all the good spots on the lifeboats; others claim that the final hours were characterized by male chivalry, in which the men valiantly gave up their positions in the boats and succumbed bravely to the depths of the Atlantic. \n",
    "\n",
    "Consider the two claims: class warfare, and male chivalry. Suppose that class warfare occurred in the final hours aboard the Titanic.  What patterns might you expect to see in the data?  Suppose that male chivalry was widespread during the final hours instead. What patterns might you then expect to see in the data?  Explain both of these hypothesized patterns in words. Are these two hypotheses mutually exclusive or not?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer**  \n",
    "Assuming that class warfare occurred and that people with first class tickets took the good spots on the lifeboats, we might find that if we divide the survival rates by class, the survival rate for first class passengers might be higher than those who weren't.  \n",
    "  \n",
    "If male chivalry came into play, we might find a few things. First, if we grouped the survival rates by gender, the survival rate for females might be higher due to men giving up their positions. Additionally, if we grouped it further by age, survival rates for boys might be higher than survival rates for adult men, seeing that the men would give up their positions for women AND children.  \n",
    "\n",
    "These hypotheses are not mutually exclusive, since class warfare and male chivalry can occur at the same time, and not just one or the other. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part C**: Use Pandas methods to create a clean data set by removing any rows from the DataFrame that are missing values corresponding to **Survived**, **Pclass**, **Age**, or **Sex**. Store the clean data in a DataFrame called dfTitanic. Be sure to show any exploratory work determining if/where there are rows with missing values. _HINT: There should be 714 rows in your cleaned data set._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reference for drop function: https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.dropna.html\n",
    "# drop rows by looking for null values in defined columns (survived,pclass,age,etc)\n",
    "dfTitanic = df.dropna(subset=['Survived', 'Pclass', 'Age', 'Sex'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part D**: Compute the probability of survival according to class, gender, and all combinations of the two variables.  Then, answer the following questions:\n",
    "* **(i)** When reviewing class survival probability, how do the results compare to the base survival probability results from **Part A**?\n",
    "* **(ii)** When reviewing gender survival probability, how do the results compare to the base survival probability results from **Part A**?\n",
    "* **(iii)** Within each passenger class, were men or women more/less/equally likely to survive?\n",
    "* **(iv)**  Did men in first class or women in third class have a higher survival probability?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "probability of survival by class (ie total survived in 1st / total passengers in 1st): \n",
      "1st:  0.64\n",
      "2nd:  0.48\n",
      "3rd:  0.25\n",
      "\n",
      "probability of survival by gender (ie total male survived / total male passengers): \n",
      "male:  0.2\n",
      "female:  0.75\n",
      "\n",
      "probability of survival by gender AND class (ie total male 1st survived / total male passengers in 1st): \n",
      "male 1st:  0.39\n",
      "male 2nd:  0.18\n",
      "male 3rd:  0.14\n",
      "female 1st:  0.96\n",
      "female 2nd:  0.93\n",
      "female 3rd:  0.53\n"
     ]
    }
   ],
   "source": [
    "# Ref for querying data frame with boolean variables: https://chrisalbon.com/python/data_wrangling/pandas_selecting_rows_on_conditions/\n",
    "# used boolean variables for code readability - was running into some issues with syntax as shown in nbs in class\n",
    "\n",
    "# define boolean variables for survived and the three classes\n",
    "survived = dfTitanic['Survived'] == 1\n",
    "first = dfTitanic['Pclass'] == 1\n",
    "second = dfTitanic['Pclass'] == 2\n",
    "third = dfTitanic['Pclass'] == 3\n",
    "\n",
    "# get total survived by class and total passengers by class\n",
    "first_surv = len(dfTitanic[survived & first])\n",
    "second_surv = len(dfTitanic[survived & second])\n",
    "third_surv = len(dfTitanic[survived & third])\n",
    "\n",
    "total_first = len(dfTitanic[first])\n",
    "total_second = len(dfTitanic[second])\n",
    "total_third = len(dfTitanic[third])\n",
    "\n",
    "# print totals / round for readability\n",
    "print(\"probability of survival by class (ie total survived in 1st / total passengers in 1st): \")\n",
    "print(\"1st: \", round(first_surv/total_first,2))\n",
    "print(\"2nd: \", round(second_surv/total_second,2))\n",
    "print(\"3rd: \", round(third_surv/total_third,2))\n",
    "print(\"\")\n",
    "\n",
    "# define boolean variables for male and female\n",
    "male = dfTitanic['Sex'] == \"male\"\n",
    "female = dfTitanic['Sex'] == \"female\"\n",
    "\n",
    "# get total survived by gender and total passengers by gender\n",
    "male_surv = len(dfTitanic[survived & male])\n",
    "female_surv = len(dfTitanic[survived & female])\n",
    "\n",
    "total_male = len(dfTitanic[male])\n",
    "total_female = len(dfTitanic[female])\n",
    "\n",
    "# print totals / round for readability \n",
    "print(\"probability of survival by gender (ie total male survived / total male passengers): \")\n",
    "print(\"male: \", round(male_surv/total_male,2))\n",
    "print(\"female: \", round(female_surv/total_female,2))\n",
    "print(\"\")\n",
    "\n",
    "# get total survived by gender and class and total passengers by gender and class\n",
    "male_first_surv = len(dfTitanic[survived & male & first])\n",
    "male_second_surv = len(dfTitanic[survived & male & second])\n",
    "male_third_surv = len(dfTitanic[survived & male & third])\n",
    "female_first_surv = len(dfTitanic[survived & female & first])\n",
    "female_second_surv = len(dfTitanic[survived & female & second])\n",
    "female_third_surv = len(dfTitanic[survived & female & third])\n",
    "\n",
    "total_male_first = len(dfTitanic[male & first])\n",
    "total_male_second = len(dfTitanic[male & second])\n",
    "total_male_third = len(dfTitanic[male & third])\n",
    "total_female_first = len(dfTitanic[female & first])\n",
    "total_female_second = len(dfTitanic[female & second])\n",
    "total_female_third = len(dfTitanic[female & third])\n",
    "\n",
    "#print totals / round for readability\n",
    "print(\"probability of survival by gender AND class (ie total male 1st survived / total male passengers in 1st): \")\n",
    "print(\"male 1st: \", round(male_first_surv/total_male_first,2))\n",
    "print(\"male 2nd: \", round(male_second_surv/total_male_second,2))\n",
    "print(\"male 3rd: \", round(male_third_surv/total_male_third,2))\n",
    "print(\"female 1st: \", round(female_first_surv/total_female_first,2))\n",
    "print(\"female 2nd: \", round(female_second_surv/total_female_second,2))\n",
    "print(\"female 3rd: \", round(female_third_surv/total_female_third,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer**  \n",
    "**(i)** As the code output above shows, 1st and 2nd class had a higher survival probability than the base survival probability (BSP), but 3rd class was lower than the BSP.  \n",
    "  \n",
    "**(ii)** With gender, males had a survival probability lower than the BSP while females had a survival probability higher than the BSP.  \n",
    "  \n",
    "**(iii)** Combining the two variables, within each class, women were more likely to survive than men. Men in 2nd and 3rd class had a survival probability higher than the BSP, while men in first had a survival rate equal to the BSP. Females in every class had a higher survival rate than the BSP.  \n",
    "  \n",
    "**(iv)** Looking at the code output, I found that women in 3rd class had a higher survival probability than men in third."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part E**: One might wonder how a passenger's age is related to the likelihood that they would survive the Titanic disaster. In addition to the \"male chivalry\" argument outlined above, you can perhaps imagine an addendum - \"women and children first!\" - as the cry to ring out across the decks. Or you might imagine the opposite - rather than \"class warfare\", it is simply healthy adults fighting to take lifeboat spots for themselves.\n",
    "\n",
    "To answer this question graphically, plot two density histograms on the same set of axes, showing the distribution of the ages of passengers who survived, and the distribution of the ages of passengers who did not. \n",
    "* Use the bin edges $[0,5,10,\\ldots,70,75,80]$ for both histograms.\n",
    "* To better distinguish between our populations, we will represent survivors with `navy` (as they were eventually rescued by ships) and those who passed away with `sandybrown`.\n",
    "* Plot both histograms on a single set of axes (there should be only one panel in the figure you create), but use Matplotlib/Pandas plotting functionality to make the faces of the histogram boxes somewhat transparent, so both histograms are visible.\n",
    "* Include a legend and label your axes.\n",
    "* Comment on the results. Does your figure suggest that some age ranges are more or less likely to have survived the disaster than other ages? Fully explain your reasoning and use your figure to justify your conclusions.\n",
    "* If you noticed some relationship between age and likelihood of survival, what is one possible explanation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAfDElEQVR4nO3df5RVdf3v8efLAcXSBGEyBAws/N4IBImAb6ZOUgakoCsVsITMtYgVKJrxFWrVl1xLV2lmsTIQv5LYVwX8ca+jciW18MddIjA0IIhcJ6/JyARIQSnLH+j7/nE20+FwZmYPc2AO7tdjrbPO3p/9+XzOe8/Aec/+7L0/WxGBmZllzxHtHYCZmbUPJwAzs4xyAjAzyygnADOzjHICMDPLKCcAM7OMSpUAJI2UtElSnaSZRbZL0pxk+zpJgwu2V0j6k6RH8sqOl/S4pJeT9y5t3x0zM0urxQQgqQK4FRgF9AMmSOpXUG0U0Dd5TQbmFmyfDmwsKJsJPBkRfYEnk3UzMztE0hwBDAXqIuKViHgXWASMLagzFrgrclYAnSV1B5DUE/ga8F9F2ixMlhcC5x/gPpiZ2QHokKJOD2Bz3no9MCxFnR5AA/BL4D+AYwvanBARDQAR0SDp4y0F0q1bt+jdu3eKkM3MbK+ampo3IqKysDxNAlCRssL5I4rWkXQusC0iaiRVpfis/T9cmkxuWImTTjqJ1atXH0g3ZmaZJekvxcrTDAHVA73y1nsCW1LWOR0YI+lVckNHZ0v676TO1rxhou7AtmIfHhHzI2JIRAyprNwvgZmZ2QFKkwBWAX0l9ZF0JDAeqC6oUw1MTK4GGg7sioiGiJgVET0jonfS7g8R8c28NpOS5UnAQ23dGTMzS6/FIaCI2CNpGrAMqAAWRMQGSVOS7fOApcBooA7YDVyW4rN/CiyRdDnwGnDRge2CmZkdCB1O00EPGTIkfA7ArH2899571NfX8/bbb7d3KNaETp060bNnTzp27LhPuaSaiBhSWD/NSWAzM+rr6zn22GPp3bs3UrHrPqw9RQQ7duygvr6ePn36pGrjqSDMLJW3336brl27+su/TEmia9eurTpCcwIws9T85V/eWvv7cQIwM8sonwMwswNy3nn3lrS/hx+e0GKd66+/nnvuuYeKigqOOOIIbrvtNoYNK5yYoHWqq6t58cUXmTkze9OROQFYaqX+Dw/p/tObATz33HM88sgjrFmzhqOOOoo33niDd999N1XbPXv20KFD8a+7MWPGMGbMmDbH19xnlCsPAZnZYaGhoYFu3bpx1FFHAdCtWzdOPPFEevfuzRtvvAHA6tWrqaqqAmD27NlMnjyZc845h4kTJzJs2DA2bNjQ2F9VVRU1NTXceeedTJs2jV27dtG7d28++OADAHbv3k2vXr147733qK2tZfjw4Zx66qlccMEF/P3vf2/s4wc/+AFnnXUWv/rVr7jvvvvo378/AwcO5MwzzzyEP50D4wRgZoeFc845h82bN3PKKafw3e9+l6eeeqrFNjU1NTz00EPcc889jB8/niVLlgC5ZLJlyxY+97nPNdY97rjjGDhwYGO/Dz/8MF/96lfp2LEjEydO5Gc/+xnr1q1jwIAB/OQnP2lst3PnTp566imuueYarrvuOpYtW8batWupri6cMKH8OAGY2WHhmGOOoaamhvnz51NZWcm4ceO48847m20zZswYjj76aAAuvvhi7rvvPgCWLFnCRRftP/nAuHHjWLx4MQCLFi1i3Lhx7Nq1i507d3LWWWcBMGnSJJ5++ul92ux1+umn861vfYvbb7+d999/v037eygcXgNWZpZpFRUVVFVVUVVVxYABA1i4cCEdOnRoHLYpvAb+ox/9aONyjx496Nq1K+vWrWPx4sXcdttt+/U/ZswYZs2axd/+9jdqamo4++yzefPNN5uNKf8z5s2bx/PPP8+jjz7KoEGDqK2tpWvXrm3Z5YPKRwBmdljYtGkTL7/8cuN6bW0tn/zkJ+nduzc1NTUAPPDAA832MX78eG688UZ27drFgAED9tt+zDHHMHToUKZPn865555LRUUFxx13HF26dOGZZ54B4He/+13j0UChP//5zwwbNozrrruObt26sXnz5qL1yoWPAMzsgBzqK7jefPNNrrjiCnbu3EmHDh349Kc/zfz589m4cSOXX345N9xwQ4uXhF544YVMnz6dH/3oR03WGTduHBdddBHLly9vLFu4cCFTpkxh9+7dnHzyyfz2t78t2nbGjBm8/PLLRAQjRoxg4MCBB7Svh4ong7PUfBlotm3cuJHPfOYz7R2GtaDY76mpyeA8BGRmllFOAGZmGeUEYGaWUU4AZmYZ5QRgZpZRqRKApJGSNkmqk7TflHnJw+DnJNvXSRqclHeStFLSWkkbJP0kr81sSa9Lqk1eo0u3W2Zm1pIW7wOQVAHcCnwFqAdWSaqOiBfzqo0C+iavYcDc5P0d4OyIeFNSR+BZSf87IlYk7W6JiJ+XbnfM7FB5e/kvS9pfp6qrWqwjie9973vcfPPNAPz85z/nzTffZPbs2W3+/E2bNvGd73yHnTt38s4773DGGWcwf/78NvcLMHr0aO655x46d+5ckv5KJc0RwFCgLiJeiYh3gUXA2II6Y4G7ImcF0FlS92R9733UHZPX4XPjgZmVlaOOOooHH3ywcfbPUrryyiu5+uqrqa2tZePGjVxxxRWtat/c3D9Lly5t85f/wZhbKE0C6AHk389cn5SlqiOpQlItsA14PCKez6s3LRkyWiCpS6ujN7NM6dChA5MnT+aWW27Zb9tf/vIXRowYwamnnsqIESN47bXXAPjWt77FlVdeyRe+8AVOPvlk7r///qJ9NzQ00LNnz8b1vVNF7J0ueq9zzz238S7hY445hh//+McMGzaMG264gYsvvrix3vLlyznvvPMAGqesvvbaa/nNb37TWGf27NncfPPNRAQzZsygf//+DBgwoHFCuuXLl/OlL32JSy65hAEDBvDWW2/xta99jYEDB9K/f//GegcqTQIo9pDJwr/im6wTEe9HxCCgJzBUUv9k+1zgU8AgoAG4ueiHS5MlrZa0evv27SnCNbMPs6lTp3L33Xeza9eufcqnTZvGxIkTWbduHd/4xje48sorG7c1NDTw7LPP8sgjjzT55K+rr76as88+m1GjRnHLLbewc+fOFmN566236N+/P88//zyzZs1ixYoVvPXWWwAsXrx4n5lCITcXUf6X9t5ZSR988EFqa2tZu3YtTzzxBDNmzKChoQGAlStXcv311/Piiy/y2GOPceKJJ7J27VrWr1/PyJEj0/3QmpAmAdQDvfLWewJbWlsnInYCy4GRyfrWJDl8ANxObqhpPxExPyKGRMSQysrKFOGa2YfZxz72MSZOnMicOXP2KX/uuee45JJLALj00kt59tlnG7edf/75HHHEEfTr14+tW7cW7feyyy5j48aNjfMADR8+nHfeeafZWCoqKvj6178O5I5ORo4cycMPP8yePXt49NFHGTt239Hy0047jW3btrFlyxbWrl1Lly5dOOmkk3j22WeZMGECFRUVnHDCCZx11lmsWrUKgKFDh9KnTx8gd1TyxBNPcO211/LMM89w3HHHteInt780CWAV0FdSH0lHAuOBwicdVAMTk6uBhgO7IqJBUqWkzgCSjga+DLyUrHfPa38BsL5Ne2JmmXHVVVdxxx13NP61XYz0r4GJvU8RA9g7/9kPf/hDBg0axKBBgxq3nXjiiXz729/moYceokOHDqxfv36f6aZh3ymnO3XqREVFReP6uHHjWLJkCX/4wx/4/Oc/z7HHHrtfXBdeeCH3338/ixcvZvz48fvEVEz+dNOnnHIKNTU1DBgwgFmzZnHdddc12S6NFhNAROwBpgHLgI3AkojYIGmKpClJtaXAK0Adub/mv5uUdwf+KGkduUTyeEQ8kmy7UdILybYvAVe3aU/MLDOOP/54Lr74Yu64447Gsi984QssWrQIgLvvvpsvfvGLzfZx/fXXU1tbS21tLQCPPfYY7733HgB//etf2bFjBz169KB3797U1tbywQcfsHnzZlauXNlkn1VVVaxZs4bbb799v+GfvcaPH8+iRYu4//77ufDCCwE488wzWbx4Me+//z7bt2/n6aefZujQ/QdFtmzZwkc+8hG++c1v8v3vf581a9Y0u48tSTUddEQsJfcln182L285gKlF2q0DTmuiz0tbFamZlZU0l20eTNdccw2//vWvG9fnzJnDt7/9bW666SYqKyubnLK5Kb///e+ZPn06nTp1AuCmm27iE5/4BCeccAJ9+vRhwIAB9O/fn8GDBzfZR0VFBeeeey533nknCxcuLFrns5/9LP/85z/p0aMH3bvnBkIuuOACnnvuOQYOHIgkbrzxRj7xiU/w0ksv7dP2hRdeYMaMGRxxxBF07NiRuXPntmofC3k6aEvN00Fnm6eDPjx4OmgzM2uRE4CZWUY5AZhZaofTkHEWtfb34wRgZql06tSJHTt2OAmUqYhgx44djSex0/BD4a1dlfrEsk8qHzw9e/akvr4e35Ffvjp16rTPdBYtcQIws1Q6duzYeEeqfTh4CMjMLKOcAMzMMsoJwMwso5wAzMwyygnAzCyjnADMzDLKCcDMLKOcAMzMMsoJwMwso5wAzMwyygnAzCyjnADMzDIqVQKQNFLSJkl1kmYW2S5Jc5Lt6yQNTso7SVopaa2kDZJ+ktfmeEmPS3o5ee9Sut0yM7OWtJgAJFUAtwKjgH7ABEn9CqqNAvomr8nA3icVvwOcHREDgUHASEnDk20zgScjoi/wZLJuZmaHSJojgKFAXUS8EhHvAouAsQV1xgJ3Rc4KoLOk7sn6m0mdjskr8tosTJYXAue3ZUfMzKx10iSAHsDmvPX6pCxVHUkVkmqBbcDjEfF8UueEiGgASN4/XuzDJU2WtFrSaj+IwsysdNIkABUpK3wmXJN1IuL9iBgE9ASGSurfmgAjYn5EDImIIZWVla1pamZmzUiTAOqBXnnrPYEtra0TETuB5cDIpGirpO4Ayfu21FGbmVmbpUkAq4C+kvpIOhIYD1QX1KkGJiZXAw0HdkVEg6RKSZ0BJB0NfBl4Ka/NpGR5EvBQG/fFzMxaocVnAkfEHknTgGVABbAgIjZImpJsnwcsBUYDdcBu4LKkeXdgYXIl0RHAkoh4JNn2U2CJpMuB14CLSrdbZmbWklQPhY+IpeS+5PPL5uUtBzC1SLt1wGlN9LkDGNGaYM3MrHR8J7CZWUY5AZiZZVSqISCzw8Xby39Z0v46VV1V0v7MyomPAMzMMspHAJbajDPWlLzPm54ZXPI+zSwdHwGYmWWUE4CZWUZ5CMjaVemHlQrnKTSzpvgIwMwso5wAzMwyygnAzCyjnADMzDLKJ4E/xM47796S9jfjjJJ2Z2btzEcAZmYZ5QRgZpZRTgBmZhnlBGBmllFOAGZmGZUqAUgaKWmTpDpJM4tsl6Q5yfZ1kgYn5b0k/VHSRkkbJE3PazNb0uuSapPX6NLtlpmZtaTFy0CTB7rfCnwFqAdWSaqOiBfzqo0C+iavYcDc5H0PcE1ErJF0LFAj6fG8trdExM9LtztmZpZWmiOAoUBdRLwSEe8Ci4CxBXXGAndFzgqgs6TuEdEQEWsAIuKfwEY8W5eZWVlIkwB6AJvz1uvZ/0u8xTqSegOnAc/nFU9LhowWSOpS7MMlTZa0WtLq7du3pwjXzMzSSJMAVKQsWlNH0jHAA8BVEfGPpHgu8ClgENAA3FzswyNifkQMiYghlZWVKcI1M7M00iSAeqBX3npPYEvaOpI6kvvyvzsiHtxbISK2RsT7EfEBcDu5oSYzMztE0iSAVUBfSX0kHQmMB6oL6lQDE5OrgYYDuyKiQZKAO4CNEfGL/AaSuuetXgCsP+C9MDOzVmvxKqCI2CNpGrAMqAAWRMQGSVOS7fOApcBooA7YDVyWND8duBR4QVJtUvaDiFgK3ChpELmholeB75Rsr8zMrEWpZgNNvrCXFpTNy1sOYGqRds9S/PwAEXFpqyI1M7OS8p3AZmYZ5ecB2IfKypWvl7S/M6tK2p1ZWfERgJlZRjkBmJlllBOAmVlG+RyAWTPeXv7LkvbXqeqqkvZn1hY+AjAzyygfAXyIzThjTXuHYGZlzEcAZmYZ5QRgZpZRTgBmZhnlBGBmllFOAGZmGeUEYGaWUU4AZmYZ5QRgZpZRTgBmZhnlBGBmllGpEoCkkZI2SaqTNLPIdkmak2xfJ2lwUt5L0h8lbZS0QdL0vDbHS3pc0svJe5fS7ZaZmbWkxQQgqQK4FRgF9AMmSOpXUG0U0Dd5TQbmJuV7gGsi4jPAcGBqXtuZwJMR0Rd4Mlk3M7NDJM0RwFCgLiJeiYh3gUXA2II6Y4G7ImcF0FlS94hoiIg1ABHxT2Aj0COvzcJkeSFwfhv3xczMWiFNAugBbM5br+dfX+Kp60jqDZwGPJ8UnRARDQDJ+8eLfbikyZJWS1q9ffv2FOGamVkaaRKAipRFa+pIOgZ4ALgqIv6RPjyIiPkRMSQihlRWVramqZmZNSNNAqgHeuWt9wS2pK0jqSO5L/+7I+LBvDpbJXVP6nQHtrUudDMza4s0CWAV0FdSH0lHAuOB6oI61cDE5Gqg4cCuiGiQJOAOYGNE/KJIm0nJ8iTgoQPeCzMza7UWnwgWEXskTQOWARXAgojYIGlKsn0esBQYDdQBu4HLkuanA5cCL0iqTcp+EBFLgZ8CSyRdDrwGXFS63TIzs5akeiRk8oW9tKBsXt5yAFOLtHuW4ucHiIgdwIjWBGtmZqXjO4HNzDLKCcDMLKOcAMzMMsoJwMwso5wAzMwyygnAzCyjnADMzDLKCcDMLKOcAMzMMsoJwMwso5wAzMwyygnAzCyjnADMzDLKCcDMLKOcAMzMMsoJwMwso5wAzMwyKtUTwcyyauXK10va35lVJe3OrE1SHQFIGilpk6Q6STOLbJekOcn2dZIG521bIGmbpPUFbWZLel1SbfIa3fbdMTOztFpMAJIqgFuBUUA/YIKkfgXVRgF9k9dkYG7etjuBkU10f0tEDEpeS5uoY2ZmB0GaI4ChQF1EvBIR7wKLgLEFdcYCd0XOCqCzpO4AEfE08LdSBm1mZm2XJgH0ADbnrdcnZa2tU8y0ZMhogaQuxSpImixptaTV27dvT9GlmZmlkSYBqEhZHECdQnOBTwGDgAbg5mKVImJ+RAyJiCGVlZUtxWpmZimlSQD1QK+89Z7AlgOos4+I2BoR70fEB8Dt5IaazMzsEEmTAFYBfSX1kXQkMB6oLqhTDUxMrgYaDuyKiIbmOt17jiBxAbC+qbpmZlZ6Ld4HEBF7JE0DlgEVwIKI2CBpSrJ9HrAUGA3UAbuBy/a2l3QvUAV0k1QP/GdE3AHcKGkQuaGiV4HvlHC/zMrSeefdW/I+H354Qsn7tGxIdSNYconm0oKyeXnLAUxtom3Rf50RcWn6MM3MrNQ8FYSZWUY5AZiZZZQTgJlZRjkBmJlllBOAmVlGOQGYmWWUnwdgdgjNOGPNQejV9wHYgfERgJlZRmXmCODt5b8saX+dqq4qaX9mZodaZhKA2YdVqaeX8NQS2eEhIDOzjHICMDPLKCcAM7OMcgIwM8soJwAzs4xyAjAzyyhfBmp2mCv93cW+DDQrfARgZpZRqRKApJGSNkmqkzSzyHZJmpNsXydpcN62BZK2SVpf0OZ4SY9Lejl579L23TEzs7RaTACSKoBbgVFAP2CCpH4F1UYBfZPXZGBu3rY7gZFFup4JPBkRfYEnk3UzMztE0hwBDAXqIuKViHgXWASMLagzFrgrclYAnSV1B4iIp4G/Fel3LLAwWV4InH8gO2BmZgcmzUngHsDmvPV6YFiKOj2Ahmb6PSEiGgAiokHSx4tVkjSZ3FEFJ510UopwzawtPHFidqQ5AlCRsjiAOgckIuZHxJCIGFJZWVmKLs3MjHQJoB7olbfeE9hyAHUKbd07TJS8b0sRi5mZlUiaBLAK6Cupj6QjgfFAdUGdamBicjXQcGDX3uGdZlQDk5LlScBDrYjbzMzaqMVzABGxR9I0YBlQASyIiA2SpiTb5wFLgdFAHbAbuGxve0n3AlVAN0n1wH9GxB3AT4Elki4HXgMuKuWOFVq58vWS9ndmVUm7MzM75FLdCRwRS8l9yeeXzctbDmBqE22L3lYYETuAEakjNTOzkvKdwGZmGeUEYGaWUU4AZmYZ5QRgZpZRTgBmZhnlBGBmllFOAGZmGeUEYGaWUU4AZmYZ5QRgZpZRfii8me3D82ZlhxPAASr1QzPAD84ws0PLQ0BmZhnlBGBmllFOAGZmGeUEYGaWUU4AZmYZ5QRgZpZRqRKApJGSNkmqkzSzyHZJmpNsXydpcEttJc2W9Lqk2uQ1ujS7ZGZmabR4H4CkCuBW4CtAPbBKUnVEvJhXbRTQN3kNA+YCw1K0vSUifl6yvTnMHYx7C8zMmpLmCGAoUBcRr0TEu8AiYGxBnbHAXZGzAugsqXvKtmZm1g7S3AncA9ict15P7q/8lur0SNF2mqSJwGrgmoj4e8q4212pb5cHGDq0R8n7NGtv5513b3uH0KKHH57Q3iG0izRHACpSFinrNNd2LvApYBDQANxc9MOlyZJWS1q9ffv2FOGamVkaaRJAPdArb70nsCVlnSbbRsTWiHg/Ij4Abic3XLSfiJgfEUMiYkhlZWWKcM3MLI00CWAV0FdSH0lHAuOB6oI61cDE5Gqg4cCuiGhorm1yjmCvC4D1bdwXMzNrhRbPAUTEHknTgGVABbAgIjZImpJsnwcsBUYDdcBu4LLm2iZd3yhpELkhoVeB75Ryx8zMrHmppoOOiKXkvuTzy+blLQcwNW3bpPzSVkVqZoelGWesKXmfNz0zuOVK1iLfCWxmllFOAGZmGeUngpnZYaf0w0q+D8DMzDLECcDMLKOcAMzMMsrnAMrIwZhfyMysKU4AZmYldjCmdu9UdVXJ+/QQkJlZRjkBmJlllBOAmVlGOQGYmWWUE4CZWUY5AZiZZZQvAzWzzCv1c4vvu6ak3R00PgIwM8soJwAzs4zyEJCZZV7pp5fuUeL+Do5URwCSRkraJKlO0swi2yVpTrJ9naTBLbWVdLykxyW9nLx3Kc0umZlZGi0mAEkVwK3AKKAfMEFSv4Jqo4C+yWsyMDdF25nAkxHRF3gyWTczs0MkzRHAUKAuIl6JiHeBRcDYgjpjgbsiZwXQWVL3FtqOBRYmywuB89u4L2Zm1gppEkAPYHPeej37D3A1Vae5tidERANA8v7x9GGbmVlbpTkJrCJlkbJOmrbNf7g0mdywEsCbkja1pn2ebsAbB9j2UCn3GMs9Pij/GMs9PnCMpXAQ4ru6LY0/WawwTQKoB3rlrfcEtqSsc2QzbbdK6h4RDclw0bZiHx4R84H5KeJslqTVETGkrf0cTOUeY7nHB+UfY7nHB46xFMo9vr3SDAGtAvpK6iPpSGA8UF1QpxqYmFwNNBzYlQzrNNe2GpiULE8CHmrjvpiZWSu0eAQQEXskTQOWARXAgojYIGlKsn0esBQYDdQBu4HLmmubdP1TYImky4HXgItKumdmZtasVDeCRcRScl/y+WXz8pYDmJq2bVK+AxjRmmDbqM3DSIdAucdY7vFB+cdY7vGBYyyFco8PAOW+u83MLGs8F5CZWUZlIgG0NJVFe5C0QNI2SevzyspmegxJvST9UdJGSRskTS+nGCV1krRS0tokvp+UU3wFsVZI+pOkR8oxRkmvSnpBUq2k1eUWo6TOku6X9FLy7/Hfyyy+f0t+dntf/5B0VTnF2JQPfQJIOZVFe7gTGFlQVk7TY+wBromIzwDDganJz61cYnwHODsiBgKDgJHJFWjlEl++6cDGvPVyjPFLETEo79LFcorxV8BjEfE/gIHkfpZlE19EbEp+doOAz5G7EOZ/llOMTYqID/UL+HdgWd76LGBWe8eVxNIbWJ+3vgnonix3Bza1d4x5sT0EfKUcYwQ+AqwBhpVbfOTufXkSOBt4pBx/z8CrQLeCsrKIEfgY8P9IzleWW3xF4j0H+D/lHGP+60N/BEC6qSzKRVlOjyGpN3Aa8DxlFGMytFJL7ibCxyOirOJL/BL4D+CDvLJyizGA30uqSe68h/KJ8WRgO/DbZBjtvyR9tIziKzQe2Pt4sXKNsVEWEkCbp6PIMknHAA8AV0XEP9o7nnwR8X7kDrt7AkMl9W/vmPJJOhfYFhE17R1LC06PiMHkhkmnSjqzvQPK0wEYDMyNiNOAtyjHoRQgudl1DHBfe8eSVhYSQJqpLMrF1mRaDJqbHuNQkdSR3Jf/3RHxYFJcVjECRMROYDm5cyrlFN/pwBhJr5KbCfdsSf9NecVIRGxJ3reRG7seSvnEWA/UJ0d3APeTSwjlEl++UcCaiNiarJdjjPvIQgJIM5VFuSib6TEkCbgD2BgRv8jbVBYxSqqU1DlZPhr4MvBSucQHEBGzIqJnRPQm9+/uDxHxTcooRkkflXTs3mVyY9jrKZMYI+KvwGZJ/5YUjQBepEziKzCBfw3/QHnGuK/2PglxiE7MjAb+L/Bn4IftHU8S071AA/Aeub9yLge6kjth+HLyfnw7xvdFckNl64Da5DW6XGIETgX+lMS3HvhxUl4W8RWJt4p/nQQumxjJjbGvTV4b9v7/KLMYBwGrk9/1/wK6lFN8SYwfAXYAx+WVlVWMxV6+E9jMLKOyMARkZmZFOAGYmWWUE4CZWUY5AZiZZZQTgJlZRjkBmJlllBOAmVlGOQGYmWXU/wcO+zaDfj2zhAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Ref: nb03 for histograms\n",
    "# Ref for plotting two histograms / make transparent a bit: https://www.kite.com/python/answers/how-to-plot-two-histograms-on-one-plot-using-matplotlib-in-python\n",
    "my_bins = range(0,80,5)\n",
    "\n",
    "#define data points for survived vs non\n",
    "survived = dfTitanic[dfTitanic['Survived'] == 1]['Age']\n",
    "dead = dfTitanic[dfTitanic['Survived'] == 0]['Age']\n",
    "\n",
    "# use matplotlib to plot the histogram with alpha of .7 to make slightly transparent\n",
    "plt.hist(survived, my_bins, label='Survivors', density=True, color='navy', alpha=0.7)\n",
    "plt.hist(dead, my_bins, label='Non-Survivors',density=True, color = 'sandybrown', alpha=0.7)\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part F:** In Part E, we plotted two *density* histograms, showing the distributions of ages of passengers that survived or did not survive the Titanic disaster. Why would it be misleading for us to have plotted these as *frequency* histograms instead?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer**  \n",
    "Using a frequency histogram would be misleading because the number of observations are not the same. By scaling it to a density histogram, we are able to draw meaningful comparisons from the data. Using a frequency histogram may lead us to false conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part G**: Do the data suggest class warfare, male chivalry, age bias, or some combination of these characteristics in the final hours aboard the Titanic?  Justify your conclusions based on the computations done above, or do any other analysis that you like, but be sure to clearly justify your conclusions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer**  \n",
    "Looking at the data, we see that those who were in a higher class tended to have a higher probability of survival. We also found that females had a higher probability of survival. The histogram of survivors by age is very slightly skewed right, which, so we found that younger people tended to survive more often than older people. It is possible that class warfare, male chivalry, age bias, or a combination of these factors played a part in who survived the Titanic. However, we cannot draw any conclusions. There is a correlation between class and survival, and gender and survival, but this does not prove causation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**P.S.** It is not a component of your graded assignment, but the 1997 James Cameron film _Titanic_ captured some of these very notions in some riveting cinema. Whether or not you found evidence for these cases in the data, you might find it interesting to watch the movie (or just the segments of the sinking) to see one interpretation of these ideas. You can perhaps see how we might be persuaded to reinterpret the evidence of data by a heart-wrenching performance from a handsome young Leonardo DiCaprio!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Appendix'></a>\n",
    "\n",
    "## Appendix \n",
    "\n",
    "*Goal*: Prove that \n",
    "$$\n",
    "\\bar{x}_n = \\bar{x}_{n-1} + \\frac{x_n - \\bar{x}_{n-1}}{n}\n",
    "$$\n",
    "\n",
    "Note that you can get an expression for $\\bar{x}_{n-1}$ by simply replacing $n$ in Equation 1 above with $n-1$.\n",
    "\n",
    "We'll start with $\\bar{x}_n$ and massage it until we get the righthand side of the formula\n",
    "\n",
    "\\begin{eqnarray}\n",
    "\\nonumber \\bar{x}_n &=& \\frac{1}{n} \\sum_{k=1}^n x_k \\\\\n",
    "&=& \\frac{1}{n} \\sum_{k=1}^{n-1} x_k + \\frac{1}{n}x_n \\\\\n",
    "&=& \\frac{n-1}{n-1}\\frac{1}{n} \\sum_{k=1}^{n-1} x_k + \\frac{1}{n}x_n \\\\\n",
    "&=& \\frac{n-1}{n} \\left(\\frac{1}{n-1} \\sum_{k=1}^{n-1} x_k\\right) + \\frac{1}{n}x_n \\\\\n",
    "&=& \\frac{n-1}{n} \\bar{x}_{n-1} + \\frac{1}{n}x_n \\\\\n",
    "&=& \\frac{n}{n}\\bar{x}_{n-1} - \\frac{1}{n}\\bar{x}_{n-1} + \\frac{1}{n}x_n \\\\\n",
    "&=&  \\bar{x}_{n-1} + \\frac{x_n - \\bar{x}_{n-1}}{n} \\quad \\checkmark\n",
    "\\end{eqnarray}\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
